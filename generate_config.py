import json
import numpy as np
from scipy.spatial.transform import Rotation as R

def generate_kitti360_configs(output_dir):
    # 1. Intrinsics [fx, fy, cx, cy]
    # data_rect ì´ë¯¸ì§€ë¥¼ ì“°ë¯€ë¡œ P_rect_00 ì˜ Kê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    intrinsics_K = [552.554261, 552.554261, 682.049453, 238.769549] 
    intrinsics_D = [0.0, 0.0, 0.0, 0.0, 0.0]

    # 2. Extrinsics GT íŒŒì‹± (calib_cam_to_velo.txt)
    cam2velo_vals = [
        0.04307104361, -0.08829286498, 0.995162929, 0.8043914418,
        -0.999004371, 0.007784614041, 0.04392796942, 0.2993489574,
        -0.01162548558, -0.9960641394, -0.08786966659, -0.1770225824
    ]
    T_cam2velo = np.eye(4)
    T_cam2velo[:3, :4] = np.array(cam2velo_vals).reshape(3, 4)
    
    # LiDAR -> Unrectified Camera ì—­í–‰ë ¬ ë³€í™˜
    T_velo2cam_unrect = np.linalg.inv(T_cam2velo)
    R_velo2cam_unrect = T_velo2cam_unrect[:3, :3]
    t_velo2cam_unrect = T_velo2cam_unrect[:3, 3]

    # ğŸŒŸ [ì‹ ê·œ ì¶”ê°€] R_rect_00 (perspective.txt ê¸°ì¤€) ë°˜ì˜
    # ì´ í–‰ë ¬ì´ ê³±í•´ì ¸ì•¼ Rectified ì´ë¯¸ì§€ì— ë§ëŠ” ì™„ë²½í•œ ì •ë‹µ(GT)ì´ ë©ë‹ˆë‹¤.
    R_rect_vals = [
        0.999974, -0.007141, -0.000089,
        0.007141,  0.999969, -0.003247,
        0.000112,  0.003247,  0.999995
    ]
    R_rect_00 = np.array(R_rect_vals).reshape(3, 3)

    # ìµœì¢… GT Matrix = R_rect * T_velo2cam
    R_gt_final = R_rect_00 @ R_velo2cam_unrect
    t_gt_final = R_rect_00 @ t_velo2cam_unrect

    # Quaternion [w, x, y, z] ë³€í™˜
    q_xyzw = R.from_matrix(R_gt_final).as_quat()
    gt_quat_wxyz = [float(q_xyzw[3]), float(q_xyzw[0]), float(q_xyzw[1]), float(q_xyzw[2])]
    gt_trans = [float(t) for t in t_gt_final]

    # ==========================================
    # 3. gt.json ìƒì„±
    # ==========================================
    gt_data = {
        "intrinsics": {"K": intrinsics_K, "D": intrinsics_D},
        "extrinsics": {"translation": gt_trans, "rotation": gt_quat_wxyz}
    }
    with open(f"{output_dir}/gt.json", 'w') as f:
        json.dump(gt_data, f, indent=4)

    # ==========================================
    # 4. config.json ìƒì„±
    # ==========================================
    # ë…¼ë¬¸ ì €ì ë°©ì‹ì˜ ê°€í˜¹í•œ ë…¸ì´ì¦ˆ (íšŒì „ +10ë„, ì´ë™ +0.2m)
    noisy_euler = R.from_quat(q_xyzw).as_euler('XYZ', degrees=True) + np.array([10.0, 10.0, 10.0])
    noisy_q_xyzw = R.from_euler('XYZ', noisy_euler, degrees=True).as_quat()
    noisy_quat_wxyz = [float(noisy_q_xyzw[3]), float(noisy_q_xyzw[0]), float(noisy_q_xyzw[1]), float(noisy_q_xyzw[2])]
    noisy_trans = [gt_trans[0] + 0.2, gt_trans[1] + 0.2, gt_trans[2] + 0.2]

    config_data = {
        "base_dir": output_dir,
        "frame_nums_per_batch": 3, # ğŸŒŸ 1ì¥ì—ì„œ 5ì¥ìœ¼ë¡œ ì¦ê°€ (ì•ˆì •ì ì¸ ê¸°í•˜í•™ì  ì œì•½ í™•ë³´)
        "overlap_nums_between_batch": 0,
        "data_params": {
            "mono_depth_model": "depth_anything_v2",
            "half_resolution": False,
            "points_down_sample_step": 2, # ì†ë„ë¥¼ ìœ„í•´ ìƒ˜í”Œë§ ë¹„ìœ¨ ì¡°ì •
            "intensity_equalization": True,
            "gray_image_equalization": True,
            "shuffle": False
        },
        "pipeline_params": {
            "mode": 0,
            "patch_size": 40,
            "init_rot_range": 10.0,
            "init_rot_resolution": 1.0,
            "coarse_trans_range": 0.2,
            "coarse_iters": 300, # ğŸŒŸ 150 -> 300 (ì¶©ë¶„í•œ íƒìƒ‰ ì‹œê°„ ë¶€ì—¬)
            "fine_trans_range": 0.2,
            "fine_iters": 300    # ğŸŒŸ 150 -> 300
        },
        "intrinsics": {"K": intrinsics_K, "D": intrinsics_D},
        "extrinsics": {"translation": noisy_trans, "rotation": noisy_quat_wxyz}
    }

    with open(f"{output_dir}/config.json", 'w') as f:
        json.dump(config_data, f, indent=4)
        
    print(f"âœ… ì„¤ì • íŒŒì¼ ì¬ìƒì„± ì™„ë£Œ! (R_rect ë°˜ì˜ ë° ìµœì í™” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©)")

if __name__ == "__main__":
    target_dir = "/home/airlab/claim/kitti360_dataset/kitti360_01" # ì°¬ì˜ë‹˜ ê²½ë¡œë¡œ ë§ì¶¤
    generate_kitti360_configs(target_dir)